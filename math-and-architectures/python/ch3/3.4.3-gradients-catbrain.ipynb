{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1100, 0.0900, 1.0000],\n",
      "        [0.0100, 0.0200, 1.0000],\n",
      "        [0.9800, 0.9100, 1.0000],\n",
      "        [0.1200, 0.2100, 1.0000],\n",
      "        [0.9800, 0.9900, 1.0000],\n",
      "        [0.8500, 0.8700, 1.0000],\n",
      "        [0.0300, 0.1400, 1.0000],\n",
      "        [0.5500, 0.4500, 1.0000],\n",
      "        [0.4900, 0.5100, 1.0000],\n",
      "        [0.9900, 0.0100, 1.0000],\n",
      "        [0.0200, 0.8900, 1.0000],\n",
      "        [0.3100, 0.4700, 1.0000],\n",
      "        [0.5500, 0.2900, 1.0000],\n",
      "        [0.8700, 0.7600, 1.0000],\n",
      "        [0.6300, 0.2400, 1.0000]])\n",
      "shape of X: torch.Size([15, 3])\n",
      "tensor([-0.8000, -0.9700,  0.8900, -0.6700,  0.9700,  0.7200, -0.8300,  0.0000,\n",
      "         0.0000,  0.0000, -0.0900, -0.2200, -0.1600,  0.6300,  0.3700])\n",
      "shape of y: torch.Size([15])\n",
      "Solution via pseudo inverse: tensor([ 1.0766,  0.8976, -0.9582])\n",
      "Loss at step 0: 14.611812591552734\n",
      "Loss at step 100: 0.2474404275417328\n",
      "Loss at step 200: 0.21770881116390228\n",
      "Loss at step 300: 0.21724514663219452\n",
      "Loss at step 400: 0.21723635494709015\n",
      "Loss at step 500: 0.21723613142967224\n",
      "Loss at step 600: 0.21723616123199463\n",
      "Loss at step 700: 0.21723617613315582\n",
      "Loss at step 800: 0.21723617613315582\n",
      "Loss at step 900: 0.21723617613315582\n",
      "model.w.data = tensor([[ 1.0766],\n",
      "        [ 0.8976],\n",
      "        [-0.9582]])\n",
      "The solution via gradient descent is tensor([ 1.0766,  0.8976, -0.9582])\n"
     ]
    }
   ],
   "source": [
    "X = torch.tensor([[0.11, 0.09], [0.01, 0.02], [0.98, 0.91],\n",
    "              [0.12, 0.21], [0.98, 0.99], [0.85, 0.87],\n",
    "              [0.03, 0.14], [0.55, 0.45], [0.49, 0.51],\n",
    "              [0.99, 0.01], [0.02, 0.89], [0.31, 0.47],\n",
    "              [0.55, 0.29], [0.87, 0.76], [0.63, 0.24]], dtype=torch.float)\n",
    "X = torch.column_stack((X, torch.ones(15)))\n",
    "y = torch.tensor([-0.8, -0.97, 0.89, -0.67, 0.97, 0.72,\n",
    "              -0.83, 0.00, 0.00, 0.00, -0.09, -0.22,\n",
    "              -0.16, 0.63, 0.37], dtype=torch.float)\n",
    "print(f\"{X}\\nshape of X: {X.shape}\")\n",
    "print(f\"{y}\\nshape of y: {y.shape}\")\n",
    "\n",
    "# Let us compute solution using pseudo inverse\n",
    "solution_pseudo = torch.matmul(torch.matmul(\n",
    "    torch.linalg.inv(torch.matmul(X.T, X)), X.T) , y)\n",
    "print(\"Solution via pseudo inverse: {}\".format(solution_pseudo))\n",
    "\n",
    "\n",
    "y = y.reshape((-1, 1))\n",
    "\n",
    "# Let us define the torch module\n",
    "class LinearModel(torch.nn.Module):\n",
    "    def __init__(self, num_features):\n",
    "        super(LinearModel, self).__init__()\n",
    "        self.w = torch.nn.Parameter(\n",
    "            torch.randn(num_features, 1))\n",
    "\n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        In the forward function we accept a Tensor of input data\n",
    "        and we must return a Tensor of output data.\n",
    "        We can use Modules defined in the constructor as\n",
    "        well as arbitrary operators on Tensors.\n",
    "        \"\"\"\n",
    "        y_pred  = torch.mm(X, self.w) # Computes Xw\n",
    "        return y_pred\n",
    "\n",
    "num_unknowns = 3\n",
    "model =  LinearModel(num_features=num_unknowns)\n",
    "# Let us use  Pytorch MSE loss function\n",
    "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-2)\n",
    "\n",
    "# Train model iteratively\n",
    "num_steps = 1000\n",
    "for step in range(num_steps):\n",
    "    y_pred = model(X)\n",
    "    loss = loss_fn(y_pred, y)\n",
    "    if step % 100 == 0:\n",
    "        print(\"Loss at step {}: {}\".format(step, loss))\n",
    "\n",
    "    # Zero the gradients before running the backward pass.\n",
    "    optimizer.zero_grad()\n",
    "    # Compute the gradients for this step\n",
    "    loss.backward()\n",
    "    # Gradient descent\n",
    "    optimizer.step()\n",
    "\n",
    "print(f\"model.w.data = {model.w.data}\")\n",
    "solution_gd = torch.squeeze(model.w.data)\n",
    "print(\"The solution via gradient descent is {}\".format(solution_gd))\n",
    "\n",
    "assert torch.allclose(solution_pseudo, solution_gd)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to PyTorch\n",
    "\n",
    "- [Learn the Basics](https://pytorch.org/tutorials/beginner/basics/intro.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quickstart\n",
    "\n",
    "https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms import ToTensor, Lambda\n",
    "from torchvision.io import read_image\n",
    "import torchvision.models as models\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "DATA_DIR = Path.home() / \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download training data from open datasets.\n",
    "training_data = datasets.FashionMNIST(\n",
    "  root=DATA_DIR,\n",
    "  train=True,\n",
    "  download=True,\n",
    "  transform=ToTensor(),\n",
    ")\n",
    "\n",
    "# Download test data from open datasets.\n",
    "test_data = datasets.FashionMNIST(\n",
    "  root=DATA_DIR,\n",
    "  train=False,\n",
    "  download=True,\n",
    "  transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "  print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "  print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n",
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Get cpu, gpu or mps device for training.\n",
    "device = (\n",
    "  \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "\n",
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.flatten = nn.Flatten()\n",
    "    self.linear_relu_stack = nn.Sequential(\n",
    "      nn.Linear(28 * 28, 512), nn.ReLU(), nn.Linear(512, 512), nn.ReLU(), nn.Linear(512, 10)\n",
    "    )\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.flatten(x)\n",
    "    logits = self.linear_relu_stack(x)\n",
    "    return logits\n",
    "\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "  size = len(dataloader.dataset)\n",
    "  model.train()\n",
    "  for batch, (X, y) in enumerate(dataloader):\n",
    "    X, y = X.to(device), y.to(device)\n",
    "\n",
    "    # Compute prediction error\n",
    "    pred = model(X)\n",
    "    loss = loss_fn(pred, y)\n",
    "\n",
    "    # Backpropagation\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    if batch % 100 == 0:\n",
    "      loss, current = loss.item(), (batch + 1) * len(X)\n",
    "      print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "  size = len(dataloader.dataset)\n",
    "  num_batches = len(dataloader)\n",
    "  model.eval()\n",
    "  test_loss, correct = 0, 0\n",
    "  with torch.no_grad():\n",
    "    for X, y in dataloader:\n",
    "      X, y = X.to(device), y.to(device)\n",
    "      pred = model(X)\n",
    "      test_loss += loss_fn(pred, y).item()\n",
    "      correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "  test_loss /= num_batches\n",
    "  correct /= size\n",
    "  print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.302699  [   64/60000]\n",
      "loss: 2.282561  [ 6464/60000]\n",
      "loss: 2.278250  [12864/60000]\n",
      "loss: 2.268418  [19264/60000]\n",
      "loss: 2.238297  [25664/60000]\n",
      "loss: 2.232692  [32064/60000]\n",
      "loss: 2.229742  [38464/60000]\n",
      "loss: 2.201360  [44864/60000]\n",
      "loss: 2.182444  [51264/60000]\n",
      "loss: 2.163365  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 45.3%, Avg loss: 2.154968 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.161929  [   64/60000]\n",
      "loss: 2.141334  [ 6464/60000]\n",
      "loss: 2.100504  [12864/60000]\n",
      "loss: 2.109572  [19264/60000]\n",
      "loss: 2.055849  [25664/60000]\n",
      "loss: 2.015914  [32064/60000]\n",
      "loss: 2.033855  [38464/60000]\n",
      "loss: 1.963130  [44864/60000]\n",
      "loss: 1.951654  [51264/60000]\n",
      "loss: 1.892297  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 58.8%, Avg loss: 1.888580 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.919180  [   64/60000]\n",
      "loss: 1.875467  [ 6464/60000]\n",
      "loss: 1.778640  [12864/60000]\n",
      "loss: 1.810668  [19264/60000]\n",
      "loss: 1.701991  [25664/60000]\n",
      "loss: 1.667272  [32064/60000]\n",
      "loss: 1.681216  [38464/60000]\n",
      "loss: 1.591548  [44864/60000]\n",
      "loss: 1.603899  [51264/60000]\n",
      "loss: 1.507396  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 61.5%, Avg loss: 1.526605 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.589341  [   64/60000]\n",
      "loss: 1.544542  [ 6464/60000]\n",
      "loss: 1.416933  [12864/60000]\n",
      "loss: 1.478207  [19264/60000]\n",
      "loss: 1.354752  [25664/60000]\n",
      "loss: 1.360819  [32064/60000]\n",
      "loss: 1.368831  [38464/60000]\n",
      "loss: 1.304087  [44864/60000]\n",
      "loss: 1.330410  [51264/60000]\n",
      "loss: 1.233489  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 63.4%, Avg loss: 1.262663 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.336177  [   64/60000]\n",
      "loss: 1.309252  [ 6464/60000]\n",
      "loss: 1.165410  [12864/60000]\n",
      "loss: 1.258971  [19264/60000]\n",
      "loss: 1.125376  [25664/60000]\n",
      "loss: 1.160519  [32064/60000]\n",
      "loss: 1.174336  [38464/60000]\n",
      "loss: 1.124293  [44864/60000]\n",
      "loss: 1.158473  [51264/60000]\n",
      "loss: 1.070683  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 64.9%, Avg loss: 1.095830 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "  print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "  train(train_dataloader, model, loss_fn, optimizer)\n",
    "  test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved PyTorch Model State to model.pth\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), \"model.pth\")\n",
    "print(\"Saved PyTorch Model State to model.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "model.load_state_dict(torch.load(\"model.pth\", weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: \"Ankle boot\", Actual: \"Ankle boot\"\n"
     ]
    }
   ],
   "source": [
    "classes = [\n",
    "  \"T-shirt/top\",\n",
    "  \"Trouser\",\n",
    "  \"Pullover\",\n",
    "  \"Dress\",\n",
    "  \"Coat\",\n",
    "  \"Sandal\",\n",
    "  \"Shirt\",\n",
    "  \"Sneaker\",\n",
    "  \"Bag\",\n",
    "  \"Ankle boot\",\n",
    "]\n",
    "\n",
    "model.eval()\n",
    "x, y = test_data[0][0], test_data[0][1]\n",
    "with torch.no_grad():\n",
    "  x = x.to(device)\n",
    "  pred = model(x)\n",
    "  predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
    "  print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets & DataLoaders\n",
    "\n",
    "https://pytorch.org/tutorials/beginner/basics/data_tutorial.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels_map = {\n",
    "  0: \"T-Shirt\",\n",
    "  1: \"Trouser\",\n",
    "  2: \"Pullover\",\n",
    "  3: \"Dress\",\n",
    "  4: \"Coat\",\n",
    "  5: \"Sandal\",\n",
    "  6: \"Shirt\",\n",
    "  7: \"Sneaker\",\n",
    "  8: \"Bag\",\n",
    "  9: \"Ankle Boot\",\n",
    "}\n",
    "figure = plt.figure(figsize=(8, 8))\n",
    "cols, rows = 3, 3\n",
    "for i in range(1, cols * rows + 1):\n",
    "  sample_idx = torch.randint(len(training_data), size=(1,)).item()\n",
    "  img, label = training_data[sample_idx]\n",
    "  figure.add_subplot(rows, cols, i)\n",
    "  plt.title(labels_map[label])\n",
    "  plt.axis(\"off\")\n",
    "  plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Custom Dataset for your files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "  \"\"\"\n",
    "  自定义图像数据集类，继承自torch.utils.data.Dataset。\n",
    "  用于加载带有注释文件的图像数据集，支持对图像和标签的转换操作。\n",
    "\n",
    "  参数:\n",
    "  - annotations_file: str, 注释文件的路径，注释文件中包含了图像文件名和对应的标签信息。\n",
    "  - img_dir: str, 存放图像文件的目录路径。\n",
    "  - transform: Callable, 可选，对图像进行转换的操作，例如裁剪、翻转等。\n",
    "  - target_transform: Callable, 可选，对标签进行转换的操作。\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
    "    # 读取注释文件，注释文件是包含图像名称和标签的CSV文件\n",
    "    self.img_labels = pd.read_csv(annotations_file)\n",
    "    # 存储图像文件的目录路径\n",
    "    self.img_dir = img_dir\n",
    "    # 对图像进行转换的操作\n",
    "    self.transform = transform\n",
    "    # 对标签进行转换的操作\n",
    "    self.target_transform = target_transform\n",
    "\n",
    "  def __len__(self):\n",
    "    \"\"\"返回数据集中图像的数量。\"\"\"\n",
    "    return len(self.img_labels)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    \"\"\"\n",
    "    根据索引idx获取并返回一个图像样本及其对应的标签。\n",
    "\n",
    "    参数:\n",
    "    - idx: int, 图像样本的索引。\n",
    "\n",
    "    返回:\n",
    "    - Tuple, 包含图像样本和其对应的标签。\n",
    "    \"\"\"\n",
    "    # 构造图像的完整路径\n",
    "    img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
    "    image = read_image(img_path)\n",
    "    # 获取对应的标签\n",
    "    label = self.img_labels.iloc[idx, 1]\n",
    "    # 如果提供了图像转换操作，则对图像进行转换\n",
    "    if self.transform:\n",
    "      image = self.transform(image)\n",
    "    # 如果提供了标签转换操作，则对标签进行转换\n",
    "    if self.target_transform:\n",
    "      label = self.target_transform(label)\n",
    "    # 返回图像样本和标签，读取的 CSV 文件类似如下：\n",
    "    # tshirt1.jpg, 0\n",
    "    # tshirt2.jpg, 0\n",
    "    # ......\n",
    "    # ankleboot999.jpg, 9\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 准备训练数据\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([64, 1, 28, 28])\n",
      "Labels batch shape: torch.Size([64])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 8\n"
     ]
    }
   ],
   "source": [
    "# Display image and label.\n",
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "# 提取第一个图像并去除多余的维度\n",
    "img = train_features[0].squeeze()\n",
    "label = train_labels[0]\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.show()\n",
    "print(f\"Label: {label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforms\n",
    "\n",
    "https://pytorch.org/tutorials/beginner/basics/transforms_tutorial.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset FashionMNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: /Users/yangjing/data\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: ToTensor()\n",
       "Target transform: Lambda()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = datasets.FashionMNIST(\n",
    "  root=DATA_DIR,\n",
    "  train=True,\n",
    "  download=True,\n",
    "  # ToTensor 将 PIL 图像或 NumPy ndarray 转换为 FloatTensor 。并将图像的像素强度值缩放到 [0., 1.] 的范围内。\n",
    "  transform=ToTensor(),\n",
    "  # Lambda 转换应用任何用户定义的 lambda 函数。在这里，我们定义一个函数将整数转换为独热编码张量。\n",
    "  # 它首先创建一个大小为 10 的零张量（我们数据集中标签的数量），并调用 scatter_，\n",
    "  # 该函数在由标签 y 给定的索引上分配一个 value=1 。\n",
    "  target_transform=Lambda(\n",
    "    lambda y: torch.zeros(10, dtype=torch.float).scatter_(0, torch.tensor(y), value=1)\n",
    "  ),\n",
    ")\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the Neural Network\n",
    "\n",
    "https://pytorch.org/tutorials/beginner/basics/buildmodel_tutorial.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义神经网络类\n",
    "class NeuralNetwork(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.flatten = nn.Flatten()\n",
    "    self.linear_relu_stack = nn.Sequential(\n",
    "      nn.Linear(28 * 28, 512),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(512, 512),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(512, 10),\n",
    "    )\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.flatten(x)\n",
    "    logits = self.linear_relu_stack(x)\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: tensor([7], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "X = torch.rand(1, 28, 28, device=device)\n",
    "# 要使用模型，我们将输入数据传递给它。这会执行模型的 forward ，以及一些后台操作。不要直接调用 model.forward() ！\n",
    "logits = model(X)\n",
    "# 在输入上调用模型返回一个二维张量，dim=0 对应于每个类别的 10 个原始预测值的输出，dim=1 对应于每个输出的单个值。\n",
    "# 我们通过将其传递给 nn.Softmax 模块的一个实例来获得预测概率。\n",
    "pred_probab = nn.Softmax(dim=1)(logits)\n",
    "y_pred = pred_probab.argmax(1)\n",
    "print(f\"Predicted class: {y_pred}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "input_image = torch.rand(3, 28, 28)\n",
    "print(input_image.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 784])\n"
     ]
    }
   ],
   "source": [
    "# 我们初始化 nn.Flatten 层，将每个 2D 28x28 图像转换为一个连续的 784 像素值数组（保持小批量维度（在 dim=0））。\n",
    "flatten = nn.Flatten()\n",
    "flat_image = flatten(input_image)\n",
    "print(flat_image.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 20])\n"
     ]
    }
   ],
   "source": [
    "# 线性层是一个模块，它使用存储的权重和偏置对输入应用线性变换。\n",
    "layer1 = nn.Linear(in_features=28 * 28, out_features=20)\n",
    "hidden1 = layer1(flat_image)\n",
    "print(hidden1.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before ReLU: tensor([[ 1.1925e-01,  4.7486e-01,  1.2103e-03,  3.1872e-02,  2.1483e-02,\n",
      "         -4.7218e-02, -4.6316e-01, -3.5146e-01, -5.4564e-01,  3.0408e-01,\n",
      "         -1.5337e-01,  1.4589e-01, -3.2466e-01,  9.2100e-01,  1.4451e-01,\n",
      "         -1.7631e-01, -1.0649e-01, -3.8257e-01,  3.4162e-01, -1.8739e-01],\n",
      "        [ 8.6719e-04,  8.3002e-02, -9.9642e-02,  1.8860e-01,  3.3531e-01,\n",
      "         -6.3137e-03, -3.7019e-01, -1.0455e-02, -8.6134e-03,  4.1513e-01,\n",
      "          8.2136e-02, -7.0921e-02, -3.1451e-01,  8.4875e-01,  7.9693e-02,\n",
      "         -1.6903e-01, -4.1167e-01, -8.2619e-02,  2.8751e-01, -9.2631e-02],\n",
      "        [ 4.0538e-01,  4.4696e-02, -1.1650e-01, -7.3744e-02,  2.2753e-01,\n",
      "         -4.1422e-02, -8.9453e-02,  1.4115e-02, -1.5648e-01,  3.7108e-01,\n",
      "         -1.1247e-02, -1.4739e-01, -2.1514e-01,  9.3629e-01,  1.4309e-01,\n",
      "         -1.1902e-01, -1.9782e-01, -4.3189e-01,  1.5192e-01, -1.9981e-02]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "\n",
      "\n",
      "After ReLU: tensor([[1.1925e-01, 4.7486e-01, 1.2103e-03, 3.1872e-02, 2.1483e-02, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 3.0408e-01, 0.0000e+00, 1.4589e-01,\n",
      "         0.0000e+00, 9.2100e-01, 1.4451e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         3.4162e-01, 0.0000e+00],\n",
      "        [8.6719e-04, 8.3002e-02, 0.0000e+00, 1.8860e-01, 3.3531e-01, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 4.1513e-01, 8.2136e-02, 0.0000e+00,\n",
      "         0.0000e+00, 8.4875e-01, 7.9693e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         2.8751e-01, 0.0000e+00],\n",
      "        [4.0538e-01, 4.4696e-02, 0.0000e+00, 0.0000e+00, 2.2753e-01, 0.0000e+00,\n",
      "         0.0000e+00, 1.4115e-02, 0.0000e+00, 3.7108e-01, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 9.3629e-01, 1.4309e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         1.5192e-01, 0.0000e+00]], grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 非线性激活是创建模型输入和输出之间复杂映射的原因。它们在线性变换之后应用，以引入非线性，帮助神经网络学习各种现象。\n",
    "print(f\"Before ReLU: {hidden1}\\n\\n\")\n",
    "hidden1 = nn.ReLU()(hidden1)\n",
    "print(f\"After ReLU: {hidden1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn.Sequential 是一个有序的模块容器。数据按照定义的顺序通过所有模块。\n",
    "# 您可以使用顺序容器快速组建一个网络，如 seq_modules 。\n",
    "seq_modules = nn.Sequential(flatten, layer1, nn.ReLU(), nn.Linear(20, 10))\n",
    "input_image = torch.rand(3, 28, 28)\n",
    "logits = seq_modules(input_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 神经网络的最后一层线性层返回 logits - 在[-infty, infty]中的原始值 - 这些值被传递到 nn.Softmax 模块。\n",
    "# logits 被缩放到[0, 1]的值，表示模型对每个类别的预测概率。 dim 参数指示值必须沿着哪个维度求和为 1。\n",
    "softmax = nn.Softmax(dim=1)\n",
    "pred_probab = softmax(logits)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model structure: NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "\n",
      "Layer: linear_relu_stack.0.weight | Size: torch.Size([512, 784]) | Values : tensor([[-0.0310, -0.0017,  0.0224,  ...,  0.0210, -0.0258,  0.0189],\n",
      "        [-0.0140, -0.0282, -0.0124,  ...,  0.0272, -0.0001, -0.0180]],\n",
      "       device='mps:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.0.bias | Size: torch.Size([512]) | Values : tensor([-0.0263, -0.0157], device='mps:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.2.weight | Size: torch.Size([512, 512]) | Values : tensor([[ 0.0364,  0.0128, -0.0437,  ..., -0.0402,  0.0137, -0.0024],\n",
      "        [-0.0248, -0.0410, -0.0374,  ...,  0.0093,  0.0293, -0.0150]],\n",
      "       device='mps:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.2.bias | Size: torch.Size([512]) | Values : tensor([0.0132, 0.0368], device='mps:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.4.weight | Size: torch.Size([10, 512]) | Values : tensor([[-0.0210, -0.0015,  0.0120,  ..., -0.0237,  0.0069, -0.0390],\n",
      "        [ 0.0282,  0.0360,  0.0107,  ...,  0.0069, -0.0198, -0.0363]],\n",
      "       device='mps:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.4.bias | Size: torch.Size([10]) | Values : tensor([0.0019, 0.0118], device='mps:0', grad_fn=<SliceBackward0>) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model structure: {model}\\n\\n\")\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "  print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatic Differentiation with `torch.autograd`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.ones(5)  # input tensor\n",
    "y = torch.zeros(3)  # expected output\n",
    "w = torch.randn(5, 3, requires_grad=True)\n",
    "b = torch.randn(3, requires_grad=True)\n",
    "z = torch.matmul(x, w) + b\n",
    "loss = torch.nn.functional.binary_cross_entropy_with_logits(z, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "此代码定义了以下计算图：\n",
    "![image.png](https://pytorch.org/tutorials/_images/comp-graph.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient function for z = <AddBackward0 object at 0x328103f70>\n",
      "Gradient function for loss = <BinaryCrossEntropyWithLogitsBackward0 object at 0x328103f70>\n"
     ]
    }
   ],
   "source": [
    "print(f\"Gradient function for z = {z.grad_fn}\")\n",
    "print(f\"Gradient function for loss = {loss.grad_fn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1926, 0.1461, 0.3292],\n",
      "        [0.1926, 0.1461, 0.3292],\n",
      "        [0.1926, 0.1461, 0.3292],\n",
      "        [0.1926, 0.1461, 0.3292],\n",
      "        [0.1926, 0.1461, 0.3292]])\n",
      "tensor([0.1926, 0.1461, 0.3292])\n"
     ]
    }
   ],
   "source": [
    "# 计算梯度\n",
    "loss.backward()\n",
    "print(w.grad)\n",
    "print(b.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# 禁用梯度追踪\n",
    "z = torch.matmul(x, w) + b\n",
    "print(z.requires_grad)\n",
    "\n",
    "# 默认情况下，所有具有 requires_grad=True 的张量都在跟踪其计算历史并支持梯度计算。\n",
    "# 然而，在某些情况下，我们不需要这样做，例如，当我们已经训练好模型并只想将其应用于一些输入数据时，\n",
    "# 即我们只想通过网络进行前向计算。我们可以通过将计算代码包围在 torch.no_grad() 块中来停止跟踪计算：\n",
    "with torch.no_grad():\n",
    "  z = torch.matmul(x, w) + b\n",
    "print(z.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "# 另一种实现相同结果的方法是对张量使用 detach() 方法：\n",
    "z = torch.matmul(x, w) + b\n",
    "z_det = z.detach()\n",
    "print(z_det.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First call\n",
      "tensor([[4., 2., 2., 2., 2.],\n",
      "        [2., 4., 2., 2., 2.],\n",
      "        [2., 2., 4., 2., 2.],\n",
      "        [2., 2., 2., 4., 2.]])\n",
      "\n",
      "Second call\n",
      "tensor([[8., 4., 4., 4., 4.],\n",
      "        [4., 8., 4., 4., 4.],\n",
      "        [4., 4., 8., 4., 4.],\n",
      "        [4., 4., 4., 8., 4.]])\n",
      "\n",
      "Call after zeroing gradients\n",
      "tensor([[4., 2., 2., 2., 2.],\n",
      "        [2., 4., 2., 2., 2.],\n",
      "        [2., 2., 4., 2., 2.],\n",
      "        [2., 2., 2., 4., 2.]])\n"
     ]
    }
   ],
   "source": [
    "# 张量梯度和雅可比乘积\n",
    "inp = torch.eye(4, 5, requires_grad=True)\n",
    "out = (inp + 1).pow(2).t()\n",
    "out.backward(torch.ones_like(out), retain_graph=True)\n",
    "print(f\"First call\\n{inp.grad}\")\n",
    "out.backward(torch.ones_like(out), retain_graph=True)\n",
    "print(f\"\\nSecond call\\n{inp.grad}\")\n",
    "inp.grad.zero_()\n",
    "out.backward(torch.ones_like(out), retain_graph=True)\n",
    "print(f\"\\nCall after zeroing gradients\\n{inp.grad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing Model Parameters\n",
    "\n",
    "https://pytorch.org/tutorials/beginner/basics/optimization_tutorial.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (linear_relu_stack): Sequential(\n",
       "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data = datasets.FashionMNIST(\n",
    "  root=DATA_DIR, train=True, download=True, transform=ToTensor()\n",
    ")\n",
    "test_data = datasets.FashionMNIST(root=DATA_DIR, train=False, download=True, transform=ToTensor())\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=64)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64)\n",
    "\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.flatten = nn.Flatten()\n",
    "    self.linear_relu_stack = nn.Sequential(\n",
    "      nn.Linear(28 * 28, 512),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(512, 512),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(512, 10),\n",
    "    )\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.flatten(x)\n",
    "    logits = self.linear_relu_stack(x)\n",
    "    return logits\n",
    "\n",
    "\n",
    "model = NeuralNetwork()\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 每个批次/周期更新模型参数的幅度。较小的值会导致学习速度缓慢，而较大的值可能会在训练过程中导致不可预测的行为\n",
    "learning_rate = 1e-3\n",
    "# 在更新参数之前，通过网络传播的数据样本数量\n",
    "batch_size = 64\n",
    "# 对数据集迭代的次数\n",
    "epochs = 5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization Loop\n",
    "\n",
    "一旦我们设置了超参数，就可以通过优化循环训练和优化我们的模型。优化循环的每次迭代称为一个周期。\n",
    "\n",
    "每个时代由两个主要部分组成：\n",
    "\n",
    "- 训练循环 - 遍历训练数据集并尝试收敛到最佳参数。\n",
    "- 验证/测试循环 - 遍历测试数据集以检查模型性能是否在改善。\n",
    "\n",
    "#### Loss Function\n",
    "\n",
    "当提供一些训练数据时，我们未训练的网络可能无法给出正确的答案。损失函数衡量获得结果与目标值之间的不相似程度，而我们希望在训练过程中最小化的正是损失函数。为了计算损失，我们使用给定数据样本的输入进行预测，并将其与真实数据标签值进行比较。\n",
    "\n",
    "常见的损失函数包括 `nn.MSELoss`（均方误差）用于回归任务，以及 `nn.NLLLoss`（负对数似然）用于分类。`nn.CrossEntropyLoss` 结合了 `nn.LogSoftmax` 和 `nn.NLLLoss` 。\n",
    "\n",
    "#### Optimizer\n",
    "\n",
    "优化是调整模型参数以减少每个训练步骤中模型误差的过程。优化算法定义了如何执行这个过程（在这个例子中我们使用随机梯度下降）。所有优化逻辑都封装在 `optimizer` 对象中。在这里，我们使用 SGD 优化器；此外，PyTorch 中还有许多不同的优化器，如 ADAM 和 RMSProp，它们在不同类型的模型和数据上表现更好。\n",
    "\n",
    "我们通过注册需要训练的模型参数并传入学习率超参数来初始化优化器。\n",
    "\n",
    "在训练循环中，优化分为三个步骤：\n",
    "\n",
    "- 调用 `optimizer.zero_grad()` 以重置模型参数的梯度。梯度默认会累加；为了防止重复计算，我们在每次迭代时显式地将其置为零。\n",
    "- 通过调用 `loss.backward()` 反向传播预测损失。PyTorch 存储每个参数的损失梯度。\n",
    "- 一旦我们得到了梯度，我们调用 `optimizer.step()` 通过在反向传播中收集的梯度来调整参数。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Implementation\n",
    "\n",
    "我们定义 `train_loop` 来循环我们的优化代码，以及 `test_loop` 来评估模型在我们的测试数据上的表现。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader: 训练数据加载器\n",
    "# model: 待训练的模型\n",
    "# criterion: 损失函数\n",
    "# optimizer: 优化器\n",
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "  # 获取数据集大小\n",
    "  size = len(dataloader.dataset)\n",
    "  # 将模型设置为训练模式\n",
    "  model.train()\n",
    "\n",
    "  # 遍历数据加载器中的每个批次\n",
    "  for batch, (X, y) in enumerate(dataloader):\n",
    "    pred = model(X)  # 做出预测\n",
    "    loss = loss_fn(pred, y)  # 计算损失\n",
    "    loss.backward()  # 反向传播损失\n",
    "    optimizer.step()  # 优化器执行一步优化\n",
    "    optimizer.zero_grad()  # 清零梯度\n",
    "\n",
    "    if batch % 100 == 0:  # 每100个批次打印一次损失和进度\n",
    "      # 获取当前损失和已完成的样本数\n",
    "      loss, current = loss.item(), batch * batch_size + len(X)\n",
    "      print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")  # 打印损失和进度\n",
    "\n",
    "\n",
    "# dataloader: 测试数据加载器\n",
    "# model: 待测试的模型\n",
    "# criterion: 损失函数\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "  model.eval()  # 将模型设置为评估模式\n",
    "  size = len(dataloader.dataset)  # 获取数据集大小\n",
    "  num_batches = len(dataloader)  # 获取批次数量\n",
    "  test_loss, correct = 0, 0  # 初始化测试损失和正确预测数\n",
    "\n",
    "  with torch.no_grad():  # 禁用梯度计算\n",
    "    for X, y in dataloader:  # 遍历数据加载器中的每个批次\n",
    "      pred = model(X)  # 做出预测\n",
    "      test_loss += loss_fn(pred, y).item()  # 累加测试损失\n",
    "      correct += (pred.argmax(1) == y).type(torch.float).sum().item()  # 累加正确预测数\n",
    "\n",
    "  test_loss /= num_batches  # 计算平均测试损失\n",
    "  correct /= size  # 计算准确率\n",
    "  print(f\"Test Error \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.294127  [   64/60000]\n",
      "loss: 0.541099  [ 6464/60000]\n",
      "loss: 0.390256  [12864/60000]\n",
      "loss: 0.492326  [19264/60000]\n",
      "loss: 0.432621  [25664/60000]\n",
      "loss: 0.415503  [32064/60000]\n",
      "loss: 0.365265  [38464/60000]\n",
      "loss: 0.515963  [44864/60000]\n",
      "loss: 0.462142  [51264/60000]\n",
      "loss: 0.509387  [57664/60000]\n",
      "Test Error \n",
      " Accuracy: 85.0%, Avg loss: 0.413701 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.259971  [   64/60000]\n",
      "loss: 0.382215  [ 6464/60000]\n",
      "loss: 0.291199  [12864/60000]\n",
      "loss: 0.380955  [19264/60000]\n",
      "loss: 0.383098  [25664/60000]\n",
      "loss: 0.384879  [32064/60000]\n",
      "loss: 0.309478  [38464/60000]\n",
      "loss: 0.507732  [44864/60000]\n",
      "loss: 0.369907  [51264/60000]\n",
      "loss: 0.432584  [57664/60000]\n",
      "Test Error \n",
      " Accuracy: 85.4%, Avg loss: 0.396890 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.214325  [   64/60000]\n",
      "loss: 0.349897  [ 6464/60000]\n",
      "loss: 0.241931  [12864/60000]\n",
      "loss: 0.335970  [19264/60000]\n",
      "loss: 0.357125  [25664/60000]\n",
      "loss: 0.369132  [32064/60000]\n",
      "loss: 0.273517  [38464/60000]\n",
      "loss: 0.480564  [44864/60000]\n",
      "loss: 0.329234  [51264/60000]\n",
      "loss: 0.381965  [57664/60000]\n",
      "Test Error \n",
      " Accuracy: 86.2%, Avg loss: 0.386446 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.214280  [   64/60000]\n",
      "loss: 0.309263  [ 6464/60000]\n",
      "loss: 0.204639  [12864/60000]\n",
      "loss: 0.260956  [19264/60000]\n",
      "loss: 0.338924  [25664/60000]\n",
      "loss: 0.313975  [32064/60000]\n",
      "loss: 0.235594  [38464/60000]\n",
      "loss: 0.432193  [44864/60000]\n",
      "loss: 0.293441  [51264/60000]\n",
      "loss: 0.327760  [57664/60000]\n",
      "Test Error \n",
      " Accuracy: 86.2%, Avg loss: 0.378452 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.194169  [   64/60000]\n",
      "loss: 0.261218  [ 6464/60000]\n",
      "loss: 0.201616  [12864/60000]\n",
      "loss: 0.256378  [19264/60000]\n",
      "loss: 0.340847  [25664/60000]\n",
      "loss: 0.294739  [32064/60000]\n",
      "loss: 0.225811  [38464/60000]\n",
      "loss: 0.348783  [44864/60000]\n",
      "loss: 0.275216  [51264/60000]\n",
      "loss: 0.291173  [57664/60000]\n",
      "Test Error \n",
      " Accuracy: 87.1%, Avg loss: 0.354122 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.186298  [   64/60000]\n",
      "loss: 0.264753  [ 6464/60000]\n",
      "loss: 0.230134  [12864/60000]\n",
      "loss: 0.229209  [19264/60000]\n",
      "loss: 0.416193  [25664/60000]\n",
      "loss: 0.251757  [32064/60000]\n",
      "loss: 0.197074  [38464/60000]\n",
      "loss: 0.339880  [44864/60000]\n",
      "loss: 0.274008  [51264/60000]\n",
      "loss: 0.269598  [57664/60000]\n",
      "Test Error \n",
      " Accuracy: 87.6%, Avg loss: 0.347140 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.170387  [   64/60000]\n",
      "loss: 0.191365  [ 6464/60000]\n",
      "loss: 0.179657  [12864/60000]\n",
      "loss: 0.199310  [19264/60000]\n",
      "loss: 0.366545  [25664/60000]\n",
      "loss: 0.250290  [32064/60000]\n",
      "loss: 0.218667  [38464/60000]\n",
      "loss: 0.289733  [44864/60000]\n",
      "loss: 0.245529  [51264/60000]\n",
      "loss: 0.290836  [57664/60000]\n",
      "Test Error \n",
      " Accuracy: 88.2%, Avg loss: 0.337078 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.142586  [   64/60000]\n",
      "loss: 0.172807  [ 6464/60000]\n",
      "loss: 0.207791  [12864/60000]\n",
      "loss: 0.209637  [19264/60000]\n",
      "loss: 0.403913  [25664/60000]\n",
      "loss: 0.262434  [32064/60000]\n",
      "loss: 0.197047  [38464/60000]\n",
      "loss: 0.330120  [44864/60000]\n",
      "loss: 0.252107  [51264/60000]\n",
      "loss: 0.230461  [57664/60000]\n",
      "Test Error \n",
      " Accuracy: 88.0%, Avg loss: 0.342077 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.115809  [   64/60000]\n",
      "loss: 0.184573  [ 6464/60000]\n",
      "loss: 0.234966  [12864/60000]\n",
      "loss: 0.174738  [19264/60000]\n",
      "loss: 0.327530  [25664/60000]\n",
      "loss: 0.250918  [32064/60000]\n",
      "loss: 0.147484  [38464/60000]\n",
      "loss: 0.301339  [44864/60000]\n",
      "loss: 0.229274  [51264/60000]\n",
      "loss: 0.239182  [57664/60000]\n",
      "Test Error \n",
      " Accuracy: 87.7%, Avg loss: 0.365297 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.149436  [   64/60000]\n",
      "loss: 0.181619  [ 6464/60000]\n",
      "loss: 0.226541  [12864/60000]\n",
      "loss: 0.209350  [19264/60000]\n",
      "loss: 0.334816  [25664/60000]\n",
      "loss: 0.217970  [32064/60000]\n",
      "loss: 0.171069  [38464/60000]\n",
      "loss: 0.261582  [44864/60000]\n",
      "loss: 0.218254  [51264/60000]\n",
      "loss: 0.181634  [57664/60000]\n",
      "Test Error \n",
      " Accuracy: 88.2%, Avg loss: 0.354440 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "epochs = 10\n",
    "for t in range(epochs):\n",
    "  print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "  train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "  test_loop(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save and Load the Model\n",
    "\n",
    "https://pytorch.org/tutorials/beginner/basics/saveloadrun_tutorial.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch 模型将学习到的参数存储在一个内部状态字典中，称为 state_dict 。这些可以通过 torch.save 方法持久化：\n",
    "model = models.vgg16(weights=\"IMAGENET1K_V1\")\n",
    "torch.save(model.state_dict(), \"model_weights.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 加载模型\n",
    "# 要加载模型权重，您需要首先创建相同模型的实例，然后使用 load_state_dict() 方法加载参数。\n",
    "model = models.vgg16()  # we do not specify ``weights``, i.e. create untrained model\n",
    "# 在下面的代码中，我们设置 weights_only=True 以限制在反序列化期间执行的函数仅限于加载权重所需的函数。\n",
    "# 使用 weights_only=True 被认为是在加载权重时的最佳实践。\n",
    "model.load_state_dict(torch.load(\"model_weights.pth\", weights_only=True))\n",
    "model.eval()\n",
    "# 在推理之前，请确保调用 model.eval() 方法以将 dropout 和批归一化层设置为评估模式。\n",
    "# 未能做到这一点将导致推理结果不一致。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用形状保存和加载模型\n",
    "\n",
    "在加载模型权重时，我们需要先实例化模型类，因为该类定义了网络的结构。我们可能希望将该类的结构与模型一起保存，在这种情况下，我们可以将 `model` （而不是 `model.state_dict()` ）传递给保存函数：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"model.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(VGG(\n",
       "   (features): Sequential(\n",
       "     (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "     (1): ReLU(inplace=True)\n",
       "     (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "     (3): ReLU(inplace=True)\n",
       "     (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "     (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "     (6): ReLU(inplace=True)\n",
       "     (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "     (8): ReLU(inplace=True)\n",
       "     (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "     (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "     (11): ReLU(inplace=True)\n",
       "     (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "     (13): ReLU(inplace=True)\n",
       "     (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "     (15): ReLU(inplace=True)\n",
       "     (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "     (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "     (18): ReLU(inplace=True)\n",
       "     (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "     (20): ReLU(inplace=True)\n",
       "     (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "     (22): ReLU(inplace=True)\n",
       "     (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "     (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "     (25): ReLU(inplace=True)\n",
       "     (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "     (27): ReLU(inplace=True)\n",
       "     (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "     (29): ReLU(inplace=True)\n",
       "     (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "   )\n",
       "   (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "   (classifier): Sequential(\n",
       "     (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "     (1): ReLU(inplace=True)\n",
       "     (2): Dropout(p=0.5, inplace=False)\n",
       "     (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "     (4): ReLU(inplace=True)\n",
       "     (5): Dropout(p=0.5, inplace=False)\n",
       "     (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "   )\n",
       " ),)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 如《保存和加载 torch.nn.Modules》中所述，保存 state_dict 被认为是最佳实践。\n",
    "# 然而，下面我们使用 weights_only=False ，因为这涉及到加载模型，这是 torch.save 的一个遗留用例。\n",
    "\n",
    "model = (torch.load(\"model.pth\", weights_only=False),)\n",
    "model\n",
    "\n",
    "# 这种方法在序列化模型时使用 Python 的 pickle 模块，因此在加载模型时依赖于实际的类定义可用。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f007212e",
      "metadata": {},
      "source": [
        "# LangGraph use human-in-loop\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8dc95951",
      "metadata": {},
      "source": [
        "## Import Models\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6cda454b",
      "metadata": {},
      "source": [
        "1. å¯¼å…¥ç›¸å…³çš„åº“ã€æ¨¡å—\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "fe4bdbcf",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from typing import Annotated\n",
        "from typing_extensions import TypedDict\n",
        "\n",
        "from langchain_tavily import TavilySearch\n",
        "from langchain_core.tools import tool\n",
        "from langgraph.checkpoint.memory import InMemorySaver\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.graph.message import add_messages\n",
        "from langgraph.prebuilt import ToolNode, tools_condition\n",
        "from langgraph.types import Command, interrupt\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b845fc5f",
      "metadata": {},
      "source": [
        "### å®šä¹‰ LangGraph çŠ¶æ€å›¾\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "2d3b3df3",
      "metadata": {},
      "outputs": [],
      "source": [
        "# from langchain.chat_models import init_chat_model\n",
        "import os\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "# llm = init_chat_model('deepseek:deepseek-chat')\n",
        "llm = ChatOpenAI(\n",
        "  model='Qwen/Qwen3-30B-A3B-Instruct-2507',\n",
        "  openai_api_key=os.environ['SILICONFLOW_API_KEY'],\n",
        "  openai_api_base='https://api.siliconflow.cn/v1',\n",
        "  streaming=True,\n",
        ")\n",
        "\n",
        "\n",
        "class State(TypedDict):\n",
        "  messages: Annotated[list, add_messages]\n",
        "\n",
        "\n",
        "graph_builder = StateGraph(State)\n",
        "\n",
        "\n",
        "@tool\n",
        "def human_assistance(query: str) -> str:\n",
        "  \"\"\"Request assistance from a human.\"\"\"\n",
        "  human_response = interrupt({'query': query})\n",
        "  return human_response['data']\n",
        "\n",
        "\n",
        "tool = TavilySearch(max_results=2)\n",
        "tools = [tool, human_assistance]\n",
        "llm_with_tools = llm.bind_tools(tools)\n",
        "\n",
        "\n",
        "def chatbot(state: State):\n",
        "  message = llm_with_tools.invoke(state['messages'])\n",
        "  assert len(message.tool_calls) <= 1\n",
        "  return {'messages': [message]}\n",
        "\n",
        "\n",
        "graph_builder.add_node('chatbot', chatbot)\n",
        "\n",
        "tool_node = ToolNode(tools=tools)\n",
        "graph_builder.add_node('tools', tool_node)\n",
        "\n",
        "graph_builder.add_conditional_edges(\n",
        "  'chatbot',\n",
        "  tools_condition,\n",
        ")\n",
        "graph_builder.add_edge('tools', 'chatbot')\n",
        "graph_builder.add_edge(START, 'chatbot')\n",
        "graph_builder.add_edge('chatbot', END)\n",
        "\n",
        "memory = InMemorySaver()\n",
        "graph = graph_builder.compile(checkpointer=memory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "6e176953",
      "metadata": {},
      "outputs": [],
      "source": [
        "# from IPython.display import Image, display\n",
        "\n",
        "# display(Image(graph.get_graph().draw_mermaid_png()))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b630421e",
      "metadata": {},
      "source": [
        "## Prompt the chatbot\n",
        "\n",
        "### çŽ°åœ¨ï¼Œå‘èŠå¤©æœºå™¨äººæå‡ºä¸€ä¸ªé—®é¢˜ï¼Œä»¥æ¿€æ´»æ–°çš„ human_assistance å·¥å…·\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "d0caf4e8",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "æˆ‘éœ€è¦ä¸€äº›ä¸“å®¶æŒ‡å¯¼æ¥æž„å»ºäººå·¥æ™ºèƒ½ä»£ç†ã€‚ä½ èƒ½å¸®æˆ‘è¯·æ±‚å¸®åŠ©å—ï¼Ÿ\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  human_assistance (019896dc6a809e9b38421b71dd774db6)\n",
            " Call ID: 019896dc6a809e9b38421b71dd774db6\n",
            "  Args:\n",
            "    query: å…³äºŽå¦‚ä½•æž„å»ºäººå·¥æ™ºèƒ½ä»£ç†çš„ä¸“å®¶æŒ‡å¯¼ï¼ŒåŒ…æ‹¬æž¶æž„è®¾è®¡ã€å…³é”®æŠ€æœ¯é€‰æ‹©ã€å¼€å‘æµç¨‹å’Œæœ€ä½³å®žè·µç­‰æ–¹é¢çš„å»ºè®®ã€‚\n"
          ]
        }
      ],
      "source": [
        "user_input = 'æˆ‘éœ€è¦ä¸€äº›ä¸“å®¶æŒ‡å¯¼æ¥æž„å»ºäººå·¥æ™ºèƒ½ä»£ç†ã€‚ä½ èƒ½å¸®æˆ‘è¯·æ±‚å¸®åŠ©å—ï¼Ÿ'\n",
        "config = {'configurable': {'thread_id': '1'}}\n",
        "\n",
        "events = graph.stream(\n",
        "  {'messages': [{'role': 'user', 'content': user_input}]},\n",
        "  config,\n",
        "  stream_mode='values',\n",
        ")\n",
        "for event in events:\n",
        "  if 'messages' in event:\n",
        "    event['messages'][-1].pretty_print()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "edd34c7d",
      "metadata": {},
      "source": [
        "èŠå¤©æœºå™¨äººç”Ÿæˆäº†ä¸€ä¸ªå·¥å…·è°ƒç”¨ï¼Œä½†éšåŽæ‰§è¡Œè¢«ä¸­æ–­ã€‚å¦‚æžœä½ æ£€æŸ¥å›¾å½¢çŠ¶æ€ï¼Œä¼šå‘çŽ°å®ƒåœ¨å·¥å…·èŠ‚ç‚¹å¤„åœæ­¢ï¼š\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "726b325e",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('tools',)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "snapshot = graph.get_state(config)\n",
        "snapshot.next"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e2545c11",
      "metadata": {},
      "source": [
        "## Resume execution\n",
        "\n",
        "è¦ç»§ç»­æ‰§è¡Œï¼Œè¯·ä¼ é€’ä¸€ä¸ªåŒ…å«å·¥å…·æ‰€éœ€æ•°æ®çš„ Command å¯¹è±¡ã€‚è¯¥æ•°æ®çš„æ ¼å¼å¯æ ¹æ®å®žé™…éœ€æ±‚è¿›è¡Œè‡ªå®šä¹‰ã€‚\n",
        "\n",
        "å¯¹äºŽè¿™ä¸ªç¤ºä¾‹ï¼Œä½¿ç”¨ä¸€ä¸ªé”®ä¸º \"data\" çš„å­—å…¸ï¼š\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "ddd3fd16",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  human_assistance (019896dc6a809e9b38421b71dd774db6)\n",
            " Call ID: 019896dc6a809e9b38421b71dd774db6\n",
            "  Args:\n",
            "    query: å…³äºŽå¦‚ä½•æž„å»ºäººå·¥æ™ºèƒ½ä»£ç†çš„ä¸“å®¶æŒ‡å¯¼ï¼ŒåŒ…æ‹¬æž¶æž„è®¾è®¡ã€å…³é”®æŠ€æœ¯é€‰æ‹©ã€å¼€å‘æµç¨‹å’Œæœ€ä½³å®žè·µç­‰æ–¹é¢çš„å»ºè®®ã€‚\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: human_assistance\n",
            "\n",
            "æˆ‘ä»¬ï¼Œä¸“å®¶åœ¨è¿™é‡Œæä¾›å¸®åŠ©ï¼æˆ‘ä»¬å»ºè®®æ‚¨æŸ¥çœ‹LangGraphä»¥æž„å»ºæ‚¨çš„ä»£ç†ã€‚å®ƒæ¯”ç®€å•çš„è‡ªä¸»ä»£ç†æ›´å¯é ã€æ›´å¯æ‰©å±•ã€‚\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "éžå¸¸æ„Ÿè°¢ä¸“å®¶çš„æŒ‡å¯¼ï¼æ ¹æ®æ‚¨æä¾›çš„å»ºè®®ï¼Œæˆ‘å°†ä¸ºæ‚¨ç®€è¦ä»‹ç»å¦‚ä½•ä½¿ç”¨ **LangGraph** æž„å»ºå¯é ä¸”å¯æ‰©å±•çš„äººå·¥æ™ºèƒ½ä»£ç†ã€‚\n",
            "\n",
            "---\n",
            "\n",
            "### ðŸš€ ä¸ºä»€ä¹ˆé€‰æ‹© LangGraphï¼Ÿ\n",
            "LangGraph æ˜¯ä¸€ä¸ªåŸºäºŽå›¾ç»“æž„çš„æ¡†æž¶ï¼Œä¸“ä¸ºæž„å»ºå¤æ‚çš„ã€å¯åä½œçš„ AI ä»£ç†è€Œè®¾è®¡ã€‚ä¸Žç®€å•çš„â€œè‡ªä¸»ä»£ç†â€ç›¸æ¯”ï¼ŒLangGraph çš„ä¼˜åŠ¿åŒ…æ‹¬ï¼š\n",
            "\n",
            "- âœ… **å¯æ‰©å±•æ€§**ï¼šæ”¯æŒå¤šæ­¥éª¤æŽ¨ç†ã€å¾ªçŽ¯å†³ç­–å’ŒåŠ¨æ€æµç¨‹ã€‚\n",
            "- âœ… **å¯è§£é‡Šæ€§**ï¼šé€šè¿‡å¯è§†åŒ–å›¾ç»“æž„æ¸…æ™°å±•ç¤ºä»£ç†çš„å†³ç­–è·¯å¾„ã€‚\n",
            "- âœ… **çµæ´»æ€§**ï¼šå¯è½»æ¾é›†æˆå¤šä¸ª LLMã€å·¥å…·ã€è®°å¿†ç³»ç»Ÿå’Œæ¡ä»¶é€»è¾‘ã€‚\n",
            "- âœ… **å¯é æ€§**ï¼šé¿å…æ— é™å¾ªçŽ¯å’Œé€»è¾‘é”™è¯¯ï¼Œæ”¯æŒè¶…æ—¶ã€é”™è¯¯å¤„ç†å’Œæ¢å¤æœºåˆ¶ã€‚\n",
            "\n",
            "---\n",
            "\n",
            "### ðŸ”§ æž„å»º AI ä»£ç†çš„å…³é”®æ­¥éª¤ï¼ˆåŸºäºŽ LangGraphï¼‰\n",
            "\n",
            "#### 1. **æ˜Žç¡®ä»£ç†çš„ç›®æ ‡ä¸Žè§’è‰²**\n",
            "   - ä¾‹å¦‚ï¼šä½ æƒ³è¦ä¸€ä¸ªâ€œé¡¹ç›®ç®¡ç†åŠ©æ‰‹â€ä»£ç†ï¼Œèƒ½åˆ¶å®šè®¡åˆ’ã€åˆ†é…ä»»åŠ¡ã€ç›‘æŽ§è¿›åº¦ã€‚\n",
            "   - å®šä¹‰å…¶æ ¸å¿ƒèƒ½åŠ›ï¼šä»»åŠ¡åˆ†è§£ã€æ—¶é—´ä¼°ç®—ã€æé†’ã€ä¸Žäººæ²Ÿé€šç­‰ã€‚\n",
            "\n",
            "#### 2. **è®¾è®¡ä»£ç†çš„å›¾ç»“æž„**\n",
            "   ä½¿ç”¨ LangGraph æž„å»ºä¸€ä¸ªæœ‰å‘å›¾ï¼ˆDAG æˆ–å¾ªçŽ¯å›¾ï¼‰ï¼Œå®šä¹‰èŠ‚ç‚¹å’Œè¾¹ï¼š\n",
            "   - **èŠ‚ç‚¹ï¼ˆNodesï¼‰**ï¼šæ¯ä¸ªèŠ‚ç‚¹ä»£è¡¨ä¸€ä¸ªå†³ç­–æˆ–æ“ä½œï¼Œå¦‚ï¼š\n",
            "     - `planning_node`ï¼šç”Ÿæˆä»»åŠ¡åˆ—è¡¨\n",
            "     - `execution_node`ï¼šæ‰§è¡Œä»»åŠ¡æˆ–è°ƒç”¨å·¥å…·\n",
            "     - `review_node`ï¼šæ£€æŸ¥ç»“æžœå¹¶å†³å®šæ˜¯å¦ç»§ç»­\n",
            "   - **è¾¹ï¼ˆEdgesï¼‰**ï¼šå®šä¹‰æµç¨‹æŽ§åˆ¶é€»è¾‘ï¼Œå¦‚æ¡ä»¶è·³è½¬ï¼š\n",
            "     ```python\n",
            "     if task_completed:\n",
            "         goto \"review_node\"\n",
            "     else:\n",
            "         goto \"retry_node\"\n",
            "     ```\n",
            "\n",
            "#### 3. **é›†æˆ LLM ä¸Žå·¥å…·**\n",
            "   - ä½¿ç”¨ LLM ä½œä¸ºâ€œå¤§è„‘â€æ¥æŽ¨ç†å’Œå†³ç­–ã€‚\n",
            "   - é›†æˆå·¥å…·ï¼ˆtoolsï¼‰å®žçŽ°å…·ä½“åŠŸèƒ½ï¼š\n",
            "     - è°ƒç”¨æ—¥åŽ† API åˆ›å»ºæé†’\n",
            "     - ç”Ÿæˆé‚®ä»¶å†…å®¹\n",
            "     - æŸ¥è¯¢çŸ¥è¯†åº“\n",
            "   - LangGraph æ”¯æŒåŠ¨æ€åœ°å°†å·¥å…·æ³¨å…¥å›¾ä¸­ã€‚\n",
            "\n",
            "#### 4. **æ·»åŠ è®°å¿†ä¸ŽçŠ¶æ€ç®¡ç†**\n",
            "   - ä½¿ç”¨ `StateGraph` ç®¡ç†ä»£ç†çš„ä¸Šä¸‹æ–‡çŠ¶æ€ï¼š\n",
            "     ```python\n",
            "     class AgentState(TypedDict):\n",
            "         tasks: List[str]\n",
            "         completed_tasks: List[str]\n",
            "         current_step: str\n",
            "         memory: str\n",
            "     ```\n",
            "   - è®©ä»£ç†èƒ½å¤Ÿè®°ä½åŽ†å²ã€é¿å…é‡å¤å·¥ä½œã€‚\n",
            "\n",
            "#### 5. **æ·»åŠ é”™è¯¯å¤„ç†ä¸Žæ¢å¤æœºåˆ¶**\n",
            "   - è®¾ç½®æœ€å¤§å°è¯•æ¬¡æ•°ã€è¶…æ—¶ã€é‡è¯•é€»è¾‘ã€‚\n",
            "   - å½“ LLM ç”Ÿæˆæ— æ•ˆè¾“å‡ºæ—¶ï¼Œå¯è§¦å‘å¤‡ç”¨è·¯å¾„ã€‚\n",
            "\n",
            "#### 6. **æµ‹è¯•ä¸Žè¿­ä»£**\n",
            "   - ç”¨çœŸå®žåœºæ™¯æµ‹è¯•ä»£ç†çš„è¡Œä¸ºã€‚\n",
            "   - ä½¿ç”¨æ—¥å¿—å’Œå¯è§†åŒ–å·¥å…·åˆ†æžå›¾çš„æ‰§è¡Œè·¯å¾„ã€‚\n",
            "   - æ ¹æ®åé¦ˆä¼˜åŒ–èŠ‚ç‚¹é€»è¾‘å’Œæç¤ºè¯ã€‚\n",
            "\n",
            "---\n",
            "\n",
            "### ðŸ“š å­¦ä¹ èµ„æºæŽ¨è\n",
            "- å®˜æ–¹æ–‡æ¡£ï¼šhttps://langchain-ai.github.io/langgraph/\n",
            "- GitHub ä»“åº“ï¼šhttps://github.com/langchain-ai/langgraph\n",
            "- ç¤ºä¾‹é¡¹ç›®ï¼š`langgraph/examples/` ä¸­åŒ…å«å¤šç§ä»£ç†æ¨¡æ¿ï¼ˆå¦‚å®¢æˆ·æ”¯æŒã€ä»£ç ç”Ÿæˆã€ä»»åŠ¡ç®¡ç†ï¼‰ã€‚\n",
            "\n",
            "---\n",
            "\n",
            "### âœ… æ€»ç»“\n",
            "ä¸è¦ä»Žâ€œå•æ­¥è‡ªåŠ¨æ‰§è¡Œâ€çš„ä»£ç†å¼€å§‹ï¼Œè€Œæ˜¯ä»¥ **LangGraph** ä¸ºåŸºç¡€ï¼Œæž„å»ºä¸€ä¸ª **å¤šé˜¶æ®µã€å¯æŽ§åˆ¶ã€æœ‰è®°å¿†çš„æ™ºèƒ½ä½“ç³»ç»Ÿ**ã€‚è¿™å°†æ˜¾è‘—æå‡ä½ çš„ AI ä»£ç†çš„ç¨³å®šæ€§ã€çµæ´»æ€§å’Œå®žç”¨æ€§ã€‚\n",
            "\n",
            "å¦‚æžœæ‚¨éœ€è¦ï¼Œæˆ‘å¯ä»¥ä¸ºæ‚¨ç”Ÿæˆä¸€ä¸ªåŸºäºŽ LangGraph çš„â€œä»»åŠ¡ç®¡ç†åŠ©ç†â€ä»£ç†çš„å®Œæ•´ä»£ç æ¨¡æ¿ã€‚æ˜¯å¦éœ€è¦ï¼Ÿ\n"
          ]
        }
      ],
      "source": [
        "human_response = 'æˆ‘ä»¬ï¼Œä¸“å®¶åœ¨è¿™é‡Œæä¾›å¸®åŠ©ï¼æˆ‘ä»¬å»ºè®®æ‚¨æŸ¥çœ‹LangGraphä»¥æž„å»ºæ‚¨çš„ä»£ç†ã€‚å®ƒæ¯”ç®€å•çš„è‡ªä¸»ä»£ç†æ›´å¯é ã€æ›´å¯æ‰©å±•ã€‚'\n",
        "\n",
        "human_command = Command(resume={'data': human_response})\n",
        "\n",
        "events = graph.stream(human_command, config, stream_mode='values')\n",
        "for event in events:\n",
        "  if 'messages' in event:\n",
        "    event['messages'][-1].pretty_print()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c77cb59e",
      "metadata": {},
      "source": [
        "è¾“å…¥å·²æŽ¥æ”¶å¹¶ä½œä¸ºå·¥å…·æ¶ˆæ¯å¤„ç†ã€‚è¯·æŸ¥çœ‹æ­¤è°ƒç”¨çš„ LangSmith è·Ÿè¸ªè®°å½•ï¼Œä»¥æŸ¥çœ‹ä¸Šè¿°è°ƒç”¨ä¸­æ‰§è¡Œçš„å…·ä½“æ“ä½œã€‚è¯·æ³¨æ„ï¼Œåœ¨ç¬¬ä¸€æ­¥ä¸­å·²åŠ è½½çŠ¶æ€ï¼Œä»¥ä¾¿æˆ‘ä»¬çš„èŠå¤©æœºå™¨äººèƒ½å¤Ÿä»Žä¸Šæ¬¡ä¸­æ–­å¤„ç»§ç»­ã€‚\n",
        "\n",
        "æ­å–œï¼æ‚¨å·²ä½¿ç”¨ interrupt ä¸ºèŠå¤©æœºå™¨äººæ·»åŠ äº†â€œäººç±»åœ¨å¾ªçŽ¯ä¸­â€æ‰§è¡ŒåŠŸèƒ½ï¼Œè¿™ä½¿å¾—åœ¨å¿…è¦æ—¶å¯å®žçŽ°äººç±»ç›‘ç£ä¸Žå¹²é¢„ã€‚æ­¤åŠŸèƒ½ä¸ºæ‚¨çš„ AI ç³»ç»Ÿå¼€è¾Ÿäº†æ›´å¤šå¯èƒ½çš„ç”¨æˆ·ç•Œé¢è®¾è®¡ç©ºé—´ã€‚ç”±äºŽæ‚¨å·²æ·»åŠ äº†æ£€æŸ¥ç‚¹ï¼Œåªè¦åº•å±‚æŒä¹…åŒ–å±‚ä»åœ¨è¿è¡Œï¼Œå›¾å½¢å¯è¢«æ— é™æš‚åœï¼Œå¹¶åœ¨ä»»ä½•æ—¶é—´ç‚¹æ¢å¤æ‰§è¡Œï¼Œä¸”æ¢å¤åŽç³»ç»ŸçŠ¶æ€ä¸Žæš‚åœå‰å®Œå…¨ä¸€è‡´ã€‚\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "learn-ai (3.12.11)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}

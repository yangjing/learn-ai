{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f007212e",
   "metadata": {},
   "source": [
    "# LangGraph Tutorial\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc95951",
   "metadata": {},
   "source": [
    "## Import Models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cda454b",
   "metadata": {},
   "source": [
    "1. 导入相关的库、模块\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4bdbcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langchain_core.messages import AnyMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b845fc5f",
   "metadata": {},
   "source": [
    "### 定义 LangGraph 状态图\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e42dd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "  messages: list[AnyMessage]\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "\n",
    "# from langchain.chat_models import init_chat_model\n",
    "# llm = init_chat_model('deepseek:deepseek-chat')\n",
    "llm = ChatOpenAI(\n",
    "  model='Qwen/Qwen3-30B-A3B-Instruct-2507',\n",
    "  openai_api_key=os.environ['SILICONFLOW_API_KEY'],\n",
    "  openai_api_base='https://api.siliconflow.cn/v1',\n",
    "  streaming=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93e392e",
   "metadata": {},
   "source": [
    "## Add tools\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f679577",
   "metadata": {},
   "source": [
    "定义图形\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d3b3df3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x1233b3b00>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_tavily import TavilySearch\n",
    "\n",
    "\n",
    "tool = TavilySearch(max_results=2)\n",
    "tools = [tool]\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "\n",
    "def chatbot(state: State):\n",
    "  return {'messages': [llm_with_tools.invoke(state['messages'])]}\n",
    "\n",
    "\n",
    "graph_builder.add_node('chatbot', chatbot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2041077c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'LangGraph 的 `node` 是什么？',\n",
       " 'follow_up_questions': None,\n",
       " 'answer': None,\n",
       " 'images': [],\n",
       " 'results': [{'url': 'https://zhuanlan.zhihu.com/p/720864252',\n",
       "   'title': '初学LangGraph 之节点、边和状态 - 知乎专栏',\n",
       "   'content': '节点（Nodes）： 是图的基本构建模块 。 每个节点代表一个特定的功能或操作，用来处理当前状态。 节点可以执行计算、修改状态，或者根据接收到的输入生成输出。 简单理解就是在节点内数据的流转是固定的。',\n",
       "   'score': 0.8737439,\n",
       "   'raw_content': None},\n",
       "  {'url': 'https://zhuanlan.zhihu.com/p/681428515',\n",
       "   'title': 'LangChain 发布的一个重要功能：LangGraph - 知乎专栏',\n",
       "   'content': 'Node. 图中最关键的元素之一是节点。每个LangGraph节点都有一个名称和其值，它可以是LCEL中的函数或可运行项。每个节点接收一个字典类型的数据，其结构',\n",
       "   'score': 0.8687491,\n",
       "   'raw_content': None}],\n",
       " 'response_time': 1.3}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 测试工具\n",
    "tool.invoke('LangGraph 的 `node` 是什么？')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b5852c",
   "metadata": {},
   "source": [
    "创建自定义 Tool 函数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97d4c3d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x1233b3b00>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "from langchain_core.messages import ToolMessage\n",
    "\n",
    "\n",
    "class BasicToolNode:\n",
    "  \"\"\"A node that runs the tools requested in the last AIMessage.\"\"\"\n",
    "\n",
    "  def __init__(self, tools: list) -> None:\n",
    "    self.tools_by_name = {tool.name: tool for tool in tools}\n",
    "\n",
    "  def __call__(self, inputs: dict):\n",
    "    if messages := inputs.get('messages', []):\n",
    "      message = messages[-1]\n",
    "    else:\n",
    "      raise ValueError('No message found in input')\n",
    "    outputs = []\n",
    "    for tool_call in message.tool_calls:\n",
    "      print(f'Call tool function: {tool_call[\"name\"]}, args: {tool_call[\"args\"]}')\n",
    "      tool_result = self.tools_by_name[tool_call['name']].invoke(tool_call['args'])\n",
    "      outputs.append(\n",
    "        ToolMessage(\n",
    "          content=json.dumps(tool_result),\n",
    "          name=tool_call['name'],\n",
    "          tool_call_id=tool_call['id'],\n",
    "        )\n",
    "      )\n",
    "    return {'messages': outputs}\n",
    "\n",
    "\n",
    "# 定义工具函数节点\n",
    "tool_node = BasicToolNode(tools=[tool])\n",
    "graph_builder.add_node('tools', tool_node)\n",
    "\n",
    "\n",
    "# 路由函数实现\n",
    "def route_tools(state: State):\n",
    "  \"\"\"\n",
    "  Use in the conditional_edge to route to the ToolNode if the last message\n",
    "  has tool calls. Otherwise, route to the end.\n",
    "  \"\"\"\n",
    "  if isinstance(state, list):\n",
    "    ai_message = state[-1]\n",
    "  elif messages := state.get('messages', []):\n",
    "    ai_message = messages[-1]\n",
    "  else:\n",
    "    raise ValueError(f'No messages found in input state to tool_edge: {state}')\n",
    "  if hasattr(ai_message, 'tool_calls') and len(ai_message.tool_calls) > 0:\n",
    "    return 'tools'\n",
    "  return END\n",
    "\n",
    "\n",
    "# The `tools_condition` function returns \"tools\" if the chatbot asks to use a tool, and \"END\" if\n",
    "# it is fine directly responding. This conditional routing defines the main agent loop.\n",
    "graph_builder.add_conditional_edges(\n",
    "  'chatbot',\n",
    "  route_tools,\n",
    "  # The following dictionary lets you tell the graph to interpret the condition's outputs as a specific node\n",
    "  # It defaults to the identity function, but if you\n",
    "  # want to use a node named something else apart from \"tools\",\n",
    "  # You can update the value of the dictionary to something else\n",
    "  # e.g., \"tools\": \"my_tools\"\n",
    "  {\n",
    "    'tools': 'tools',\n",
    "    END: END,\n",
    "  },\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9665876e",
   "metadata": {},
   "source": [
    "使用预定义的工具函数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b93f2e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "# tool_node = ToolNode(tools=[tool])\n",
    "# graph_builder.add_node('tools', tool_node)\n",
    "\n",
    "# graph_builder.add_conditional_edges(\n",
    "#   'chatbot',\n",
    "#   tools_condition,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8eca857",
   "metadata": {},
   "source": [
    "## Add memory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0505166c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "\n",
    "memory = InMemorySaver()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c2d3dd",
   "metadata": {},
   "source": [
    "构建并编译图\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9226da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Any time a tool is called, we return to the chatbot to decide the next step\n",
    "graph_builder.add_edge('tools', 'chatbot')\n",
    "graph_builder.add_edge(START, 'chatbot')\n",
    "graph = graph_builder.compile(checkpointer=memory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e176953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.display import Image, display\n",
    "\n",
    "# display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b630421e",
   "metadata": {},
   "source": [
    "### 选择一个主题（thread id）作为本次对话的关键词。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc872690",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {'configurable': {'thread_id': '1'}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b37571c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def stream_graph_updates(user_input: str):\n",
    "#   for event in graph.stream(\n",
    "#     {'messages': [{'role': 'user', 'content': user_input}]},\n",
    "#     config,\n",
    "#     stream_mode='values',\n",
    "#   ):\n",
    "#     for value in event.values():\n",
    "#       print('Assistant:', value['messages'][-1].content)\n",
    "\n",
    "\n",
    "# while True:\n",
    "#   try:\n",
    "#     user_input = input('User: ')\n",
    "#     if user_input.lower() in ['quit', 'exit', 'q']:\n",
    "#       print('Goodbye!')\n",
    "#       break\n",
    "\n",
    "#     stream_graph_updates(user_input)\n",
    "#   except Exception:\n",
    "#     # fallback if input() is not available\n",
    "#     user_input = 'What do you know about LangGraph?'\n",
    "#     print('User: ' + user_input)\n",
    "#     stream_graph_updates(user_input)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b232c4a0",
   "metadata": {},
   "source": [
    "### 使用 thread id: 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b874b7bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "你好！我的名字叫 杨景\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "你好，杨景！很高兴认识你。有什么我可以帮你的吗？\n"
     ]
    }
   ],
   "source": [
    "user_input = '你好！我的名字叫 杨景'\n",
    "\n",
    "# The config is the **second positional argument** to stream() or invoke()!\n",
    "events = graph.stream(\n",
    "  {'messages': [{'role': 'user', 'content': user_input}]},\n",
    "  config,\n",
    "  stream_mode='values',\n",
    ")\n",
    "for event in events:\n",
    "  event['messages'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a77637fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "还记得我的名字吗？\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "当然记得，你的名字是杨景！😊 有什么问题或话题想和我聊聊吗？\n"
     ]
    }
   ],
   "source": [
    "user_input = '还记得我的名字吗？'\n",
    "\n",
    "# The config is the **second positional argument** to stream() or invoke()!\n",
    "events = graph.stream(\n",
    "  {'messages': [{'role': 'user', 'content': user_input}]},\n",
    "  config,\n",
    "  stream_mode='values',\n",
    ")\n",
    "for event in events:\n",
    "  event['messages'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b448bed",
   "metadata": {},
   "source": [
    "### 使用 thread id: 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "58d04511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "还记得我的名字吗？\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "我无法记住用户的名字或之前的对话内容，因为每次对话都是独立的。如果您愿意，可以告诉我您的名字，我会在本次对话中使用它来称呼您。\n"
     ]
    }
   ],
   "source": [
    "# 使用不同的 thread_id 进行对话\n",
    "events = graph.stream(\n",
    "  {'messages': [{'role': 'user', 'content': user_input}]},\n",
    "  {'configurable': {'thread_id': '2'}},  # change the `thread_id` here to '2' instead of '1'\n",
    "  stream_mode='values',\n",
    ")\n",
    "for event in events:\n",
    "  event['messages'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6523a41f",
   "metadata": {},
   "source": [
    "### 检查 state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "983c8d9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateSnapshot(values={'messages': [HumanMessage(content='你好！我的名字叫 杨景', additional_kwargs={}, response_metadata={}, id='bb453236-b335-4912-af74-46aa66c4184d'), AIMessage(content='你好，杨景！很高兴认识你。有什么我可以帮你的吗？', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'Qwen/Qwen3-30B-A3B-Instruct-2507'}, id='run--d8ba66dd-0cb8-46cf-9748-078eedbc2f5d-0', usage_metadata={'input_tokens': 31025, 'output_tokens': 135, 'total_tokens': 31160, 'input_token_details': {}, 'output_token_details': {}}), HumanMessage(content='还记得我的名字吗？', additional_kwargs={}, response_metadata={}, id='7ff4d74e-0f0c-47bd-a8aa-10182573161b'), AIMessage(content='当然记得，你的名字是杨景！😊 有什么问题或话题想和我聊聊吗？', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'Qwen/Qwen3-30B-A3B-Instruct-2507'}, id='run--3649833e-7d98-4fdf-add5-ddfe7e3e97f9-0', usage_metadata={'input_tokens': 42665, 'output_tokens': 252, 'total_tokens': 42917, 'input_token_details': {}, 'output_token_details': {}})]}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f07656f-9ef0-682c-8004-7b19879487b0'}}, metadata={'source': 'loop', 'step': 4, 'parents': {}}, created_at='2025-08-11T02:00:38.094213+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f07656f-8861-63fe-8003-c962908807c7'}}, tasks=(), interrupts=())"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snapshot = graph.get_state(config)\n",
    "snapshot"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-ai (3.12.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
